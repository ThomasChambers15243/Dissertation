%%
%% This is file `sample-manuscript.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `manuscript')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-manuscript.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[manuscript,screen,review,sigconf]{acmart}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Can Large Language Models Generated Code For Small-Scale Problems That Is Competitive To Model, Human-Written Code}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Thomas D. Chambers}
\email{tc262389@falmouth.ac.uk}
\affiliation{%
  \institution{Falmouth University}
  \city{Penryn}
  \state{Cornwall}
  \country{United Kingdom}
  \postcode{TR10 9FE}
}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Trovato and Tobin, et al.}



%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}

\end{CCSXML}

%\ccsdesc[500]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc[300]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc[100]{Do Not Use This Code~Generate the Correct Terms for Your Paper}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
%\keywords{Do, Not, Us, This, Code, Put, the, Correct, Terms, for,
  %Your, Paper}

\received{20 February 2007}
\received[revised]{12 March 2009}
\received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
% What is the study in a few words
This study will be investigating the practicality of using large-language models to generate code. These models take in a human-written prompt to generate an output, hopefully fulfilling the desired task of the prompt. Within the last few years, these models have been used to generate code in many languages, straight into a programmer's IDE. With many large tech companies investing in generative models, such as Google and META \cite{Google_AI_2023, Meta_2023}, and bespoke versions of these models being used commercially for code productivity, such as Github's Copilot and Sourcery \cite{GitHub_2021, Sourcery_2023}, their use by programmers, new and old, are rapidly increasing. Due to the black-box nature of these models, an intimate understanding of how these code snippets are generated is unknown, and there's a risk that poorly written, buggy and insecure code could be used by novice and experienced programmers alike. The need to understand the level of quality of outputs is paramount before these generation tools become widespread in education and industry.

\section{Understanding Generated Code}
% History of Code Generation
Code generation is not new, being used in many computing processes already, perhaps most well know is the use in compilers to produce code optimisation and executable machine code. However, even generating code from a human prompt has been discussed for over 50 years. PROW \cite{PROW} was an early code generation tool that could produce Perl code from an input written in predicate calculus. However, as discussed two years later by Manna and Waldinger \cite{Program_Syn} Toward automatic program synthesis paper], "programmers might find such a language lacking in readability and conciseness." They went on to predict that a program synthesiser that works with the programmer to produce segments of code that can be incorporated into the program would be a "more practical system" with greater "power".

% Public release of ChatGPT has blown up popularity
Fifty years later, the public release of ChatGPT back in late November 2022 [CITE HERE https://www.forbes.com/sites/bernardmarr/2023/05/19/a-short-history-of-chatgpt-how-we-got-to-where-we-are-today/], caused the public awareness of LLM  to skyrocket. Generation models have been used for years to write essays, generate art and synthesise an actor's voice, the implications of such have sent shock waves through educational and legal environments, but more recently the use of generation has become more relevant in a programmer's workflow. Codex, an OpenAI model fine-tuned on GPT-3, was released in June 2021, with 54 million public Github repositories in its training set\cite{CodexRelPaper}. Github's Copilot is a competitor to Codex, also fine-tuned on repositories Copilot can be directly integrated into IDE's to produce code-completion for entire scripts, similar to Intellisence.

% Generated code evolution up to codex then CoPilot
\subsection{Functional Success of LLM}
% How do LLM work roughly (not super important for this paper but it does need to be in here. Almost all papers leave it out as assumed knowledge so just a quick overview is sufficient)
The rising popularity of LLM generation is mainly due to their apparent success at task completion, giving them the appearance of being \textit{intelligent}. However, LLM are only prediction models. [ WRITE MORE HERE ABOUT HOW THEY WORK]

% The functional success of LLM on CS1 and now CS2 problems

Codex showed significant performance on OpenAI's HumanEval dataset\cite{CodexRelPaper} and can frequently pass CS1 and even CS2 questions \cite{Codex_CS1_CS2_Test}. 
% The lack of static code analysis for readability and maintainability (there is some, mention it, but there should be more

\subsection{Why Write Good Code}
% Importance of code analysis, reference Dijkstra, maybe clean code and Goole/Ibm

\subsection{Code Analysis}
% Write about different code metrics and how they've been used to measure student work

\subsection{Generated Code and its Performance}
% Very little research into the performance and quality of generated code. Reference the importance of such. Especially since it could be a great learning tool, the quality of what it teaches is vital.

\section{Aim of Research}
% Can generated code compare to model, human answers in performance?
% Can generated code compare to model, human answers in quality?

\section{Issues and Implications of the Study}
% Students could become too reliant
% Students could pass of generated code as their own in the same way humanity students can with ChatGPT. This has far-reaching implications. 
% 

%% The acknowledgements section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
Thank you Joseph Walton-Rivers for providing the model answers
\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}


\end{document}
\endinput
%%
%% End of file `sample-manuscript.tex'.
